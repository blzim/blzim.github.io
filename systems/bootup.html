<!DOCTYPE html>
<html>
<head>
<title>Hardware</title>
<link rel="stylesheet" type="text/css" href="../ZimStyles.css">
</head>
<body>

The Boot Up Process
<p>
The two stages of bootup are: Getting the hardware to run it's firmware, then getting the Operating System running from a storage device into memory.
</p><p>
In the past the OS was written into the hardware. Early portable OSes were booted from floppy disks. Common storage devices today are Hard Drives or Solid State Drives. With system on a chip (SoC), single board or mobile devices, the OS might be stored directly on the processor chip, or on some other chip based storage like Secure Digital (SD), MultiMediaCard (MMC), or embedded MMC (eMMC).
</p><p>
Power On Self Test (POST). POST checks that the hardware is working correctly. POST will either use a system of beep codes or a display on the motherboard if it runs into errors. The system manufacturer usually provides a table of POST codes to help with trouble shooting.
</p><p>
<table><td>
<img src="Linuxboot.jpg">
</td><td>
Boot order is set from the BIOS "System Setup", traditionally stored in a Complimentary Metal Oxide Semiconductor (CMOS) chip. Systems are moving from CMOS to FLASH to store the BIOS settings. System Setup is sometimes called "CMOS" or "NVRAM". It searches it's boot devices for boot code. 
</p><p>
Control passes to the first block of the primary boot device. Storage drives have been formatted in 512 byte sector blocks. In 2009, Storage started moving to 4096 byte sectors called Advanced Format (AF) or 4K drives, much more efficient in larger capacities.
</p><p>
The Master Boot Record (MBR), is being replaced by the GUID Partition Table (GPT) which allows for many more partitions and works with larger storage devices.
</td></table>
</p><p>
The first block of the boot device contains a partition table and a boot loader program that points to the boot program of the selected Operating System. Windows is called the "Windows Bootloader", Macs use the "Darwin Bootloader", Linux was called Linux Loader (Lilo), but has been replaced by the Grand Unified Bootloader (GRUB).
</p><p>
The Boot loader provides a menu allowing the user to select which Operating System to run on systems that have multiple OSes installed. This process is sometimes called a chainloader or chainloading Operating Systems.
</p><p>
The Operating system start sequences might vary slightly. In Linux, GRUB loads its core into RAM, which allows it to access storage and filesystems and executes the kernel, (the compressed Linux kernel is called vmlinuz). Here is where user space starts. The kernel runs the initrd (initial ramdisk), which then runs the drivers needed to run the rest of the kernel and OS including the real root filesystem.
</p><p>
The kernel does not talk to the BIOS or UEFI and can't get data from disks without drivers. In order to get the right driver to run the storage hardware it needs to load the driver file. In order to load the driver file it needs a filesystem. To fix this cycle, the kernel loads a small generic filesystem called initramfs or the initial RAM filesystem into RAM, loads the storage drivers it needs, then hands control over to the real root filesystem, which continues to load the rest of the OS.
</p><p>
Since Windows 8, Microsoft started requiring vendors to use secure boot, which will only load a digitally signed boot loader. This was done to prevent rootkit malware from taking control of the boot process. Unfortunately this also broke traditional Linux dual booting. Some Linux distros now have a secure boot signature.
</p><p>
Windows will also replace the software boot loader if it has been changed, wiping out any alternative boot options. Many dual boot users have switched to installing other OSes like Linux on their own disk, then using the boot order from BIOS System Setup to select which disk to boot from.
</p><p>
Users with single disk systems have been using "hosted hypervisors" or Virtual Environment software like VmWare Player or Oracle VirtualBox, to run their OS of choice inside a Virtual Machine.
</p><p>
Hypervisor or virtual machine monitor (VMM) is computer software, firmware or hardware that creates and runs virtual machines. A computer on which a hypervisor runs one or more virtual machines is called a host machine, and each virtual machine is called a guest machine. 
</p><p>
The hypervisor presents the guest operating systems with a virtual operating platform and manages the execution of the guest operating systems. Multiple instances of a variety of operating systems may share the vitalized hardware resources: for example, Linux, Windows, and macOS instances can all run on a single physical x86 machine. 
</p><p>
This contrasts with operating-system-level Virtualization, where all instances (usually called containers) must share a single kernel, though the guest operating systems can differ in user space, such as different Linux distributions with the same kernel.
</p><p>
The term hypervisor is a variant of supervisor, a traditional term for the kernel of an operating system: the hypervisor is the supervisor of the supervisor.
</p><p>
Native or bare metal Hypervisors run directly on the host's hardware to control the hardware and to manage guest operating systems. 
</p><p>
Hosted hypervisors run on a conventional operating system (OS) just as other computer programs do. A guest operating system runs as a process on the host. 
</p><p>
<a href="operatingSystems.html">Next Page: Operating Systems</a>
</p>

</body>
</html>